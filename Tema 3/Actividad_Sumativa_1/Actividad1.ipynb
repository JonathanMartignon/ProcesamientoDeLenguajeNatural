{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Martiñón Luna Jonathan José\n",
    "## Tema 3\n",
    "## Actividad Sumativa 1\n",
    "### Octubre 7, 2020\n",
    "### Licenciatura en Ciencia de Datos\n",
    "### Materia: Procesamiento de Lenguaje Natural\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizamos la lectura de los archivos txt\n",
    "\n",
    "aux = open('./DulceMaríaLoynaz.txt','r') # Abrimos el archivo en modo lectura\n",
    "text1 = aux.read() # Asignamos el primer texto\n",
    "aux.close() # Cerramos el archivo\n",
    "\n",
    "aux = open('./ultimaInocencia.txt','r') # Abrimos el archivo en modo lectura\n",
    "text2 = aux.read() # Asignamos el segundo texto\n",
    "aux.close() # Cerramos el archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exploración de los archivos.\n",
    "\n",
    "Existen elementos que no nos serán de utilidad, únicamente sirven cómo indicadores para la ''presentación'', tales cómo los saltos de línea \"**\\n**\", o incluso los signos de puntuación. \n",
    "\n",
    "A continuación se muestran los textos leídos. El primer caso será el texto en su forma final, es decir, una vez interpretados los saltos de línea. El segundo caso será el texto mostrando los indicadores, para apreciarlo en su ''forma cruda''."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto aplicando indicadores:\n",
      "\n",
      "“He de amoldarme a ti como el río a su cauce, como el mar a su playa, como la espada a su vaina.\n",
      "He de correr en ti, he de cantar en ti, he de guardarme en ti ya para siempre.\n",
      "Fuera de ti ha de sobrarme el mundo como le sobra al río el aire, al mar la tierra, a la espada la mesa del convite.\n",
      "Dentro de ti no ha de faltarme blandura de limo para mi corriente, perfil de viento para mis olas, ceñidura y reposo para mi acero.”\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "\n",
      "Texto con todos los indicadores:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'“He de amoldarme a ti como el río a su cauce, como el mar a su playa, como la espada a su vaina.\\nHe de correr en ti, he de cantar en ti, he de guardarme en ti ya para siempre.\\nFuera de ti ha de sobrarme el mundo como le sobra al río el aire, al mar la tierra, a la espada la mesa del convite.\\nDentro de ti no ha de faltarme blandura de limo para mi corriente, perfil de viento para mis olas, ceñidura y reposo para mi acero.”'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para el texto ''Dulce María Loynaz''\n",
    "print(\"Texto aplicando indicadores:\\n\")\n",
    "print(text1)\n",
    "print(\"-----------------------------------------------\")\n",
    "print(\"-----------------------------------------------\")\n",
    "print(\"-----------------------------------------------\")\n",
    "print(\"\\nTexto con todos los indicadores:\")\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto aplicando indicadores:\n",
      "\n",
      "Partir\n",
      "en cuerpo y alma\n",
      "partir.\n",
      "Partir\n",
      "deshacerse de las miradas\n",
      "piedras opresoras\n",
      "que duermen en la garganta.\n",
      "\n",
      "He de partir\n",
      "no más inercia bajo el sol\n",
      "no más sangre anonadada\n",
      "no más fila para morir.\n",
      "\n",
      "He de partir\n",
      "\n",
      "Pero arremete ¡viajera!\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "\n",
      "Texto con todos los indicadores:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Partir\\nen cuerpo y alma\\npartir.\\nPartir\\ndeshacerse de las miradas\\npiedras opresoras\\nque duermen en la garganta.\\n\\nHe de partir\\nno más inercia bajo el sol\\nno más sangre anonadada\\nno más fila para morir.\\n\\nHe de partir\\n\\nPero arremete ¡viajera!'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para el texto ''Ultima inocencia''\n",
    "print(\"Texto aplicando indicadores:\\n\")\n",
    "print(text2)\n",
    "print(\"-----------------------------------------------\")\n",
    "print(\"-----------------------------------------------\")\n",
    "print(\"-----------------------------------------------\")\n",
    "print(\"\\nTexto con todos los indicadores:\")\n",
    "text2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Preprocesamiento.\n",
    "\n",
    "En esta sección procederemos a limpiar los textos, pues tal como identificamos en la sección anterior, no todas las palabras (atendiendo a la definición del curso) serán de utilidad. Para ser más precisos, eliminaremos signos de puntuación.\n",
    "\n",
    "Se consideró eliminar acentos, pero después de pensarlo cuidadosamente, se llegó a la conclusión de que era un factor importante al momento de diferenciar palabras. Por ejemplo:\n",
    "\n",
    "- **Sí** Afirmativo\n",
    "- **Si** Condicional\n",
    "\n",
    "Al realizar un cambio de tipo de cadena a lista de palabras, se encontró que eliminó automáticamente los saltos de línea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpia_texto(texto):\n",
    "    \"\"\"\n",
    "    @author: Jonathan Martiñón\n",
    "    \n",
    "    La presente función recibe un texto y se encargará de eliminar \n",
    "    aquellos caracteres que no sean una palabra perteneciente al\n",
    "    Español.\n",
    "    \n",
    "    Parámetros:\n",
    "    \n",
    "    texto   Será la(s) frase(s) a limpiar en una sola variable    STR\n",
    "    \"\"\"\n",
    "    \n",
    "    texto = texto.split() # En este punto nos encargamos de eliminar los espacios\n",
    "                          # Y convertir nuestro texto en una lista de palabras.\n",
    "    \n",
    "    # Hacemos una lista con todos aquellos elementos a eliminar.\n",
    "    eliminar=[\"!\",\"¡\",\".\",\"?\", \"¿\", \",\", \".\", \";\", \":\",'\"',\"'\",'“','”']\n",
    "    \n",
    "    texto_limpio = []\n",
    "    \n",
    "    #Ahora procedemos a analizar cada palabra independientemente\n",
    "    for palabra in texto:\n",
    "        \n",
    "        aux = ''\n",
    "        for letra in palabra:\n",
    "            if not letra in eliminar:\n",
    "                aux+= letra\n",
    "                \n",
    "        aux = aux.capitalize() \n",
    "        # Ajustamos la palabra a un estándar para evitar que cuente\n",
    "        # 'Hola' y 'hola' como palabras distintas.\n",
    "        # Se eligió Capitalizar por motivos meramente estéticos.\n",
    "        # Se capitalizó después, debido a que podían existir caracteres\n",
    "        # iniciales que afectaran el funcionamiento\n",
    "                \n",
    "        texto_limpio.append(aux) # Añadimos la palabra limpia a nuestra lista de palabras\n",
    "        \n",
    "    return texto_limpio\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observamos las diferencias antes y después de aplicar la limpieza para el texto 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“He', 'de', 'amoldarme', 'a', 'ti', 'como', 'el', 'río', 'a', 'su', 'cauce,', 'como', 'el', 'mar', 'a', 'su', 'playa,', 'como', 'la', 'espada', 'a', 'su', 'vaina.', 'He', 'de', 'correr', 'en', 'ti,', 'he', 'de', 'cantar', 'en', 'ti,', 'he', 'de', 'guardarme', 'en', 'ti', 'ya', 'para', 'siempre.', 'Fuera', 'de', 'ti', 'ha', 'de', 'sobrarme', 'el', 'mundo', 'como', 'le', 'sobra', 'al', 'río', 'el', 'aire,', 'al', 'mar', 'la', 'tierra,', 'a', 'la', 'espada', 'la', 'mesa', 'del', 'convite.', 'Dentro', 'de', 'ti', 'no', 'ha', 'de', 'faltarme', 'blandura', 'de', 'limo', 'para', 'mi', 'corriente,', 'perfil', 'de', 'viento', 'para', 'mis', 'olas,', 'ceñidura', 'y', 'reposo', 'para', 'mi', 'acero.”']\n"
     ]
    }
   ],
   "source": [
    "Prueba = text1.split()\n",
    "print(Prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He', 'De', 'Amoldarme', 'A', 'Ti', 'Como', 'El', 'Río', 'A', 'Su', 'Cauce', 'Como', 'El', 'Mar', 'A', 'Su', 'Playa', 'Como', 'La', 'Espada', 'A', 'Su', 'Vaina', 'He', 'De', 'Correr', 'En', 'Ti', 'He', 'De', 'Cantar', 'En', 'Ti', 'He', 'De', 'Guardarme', 'En', 'Ti', 'Ya', 'Para', 'Siempre', 'Fuera', 'De', 'Ti', 'Ha', 'De', 'Sobrarme', 'El', 'Mundo', 'Como', 'Le', 'Sobra', 'Al', 'Río', 'El', 'Aire', 'Al', 'Mar', 'La', 'Tierra', 'A', 'La', 'Espada', 'La', 'Mesa', 'Del', 'Convite', 'Dentro', 'De', 'Ti', 'No', 'Ha', 'De', 'Faltarme', 'Blandura', 'De', 'Limo', 'Para', 'Mi', 'Corriente', 'Perfil', 'De', 'Viento', 'Para', 'Mis', 'Olas', 'Ceñidura', 'Y', 'Reposo', 'Para', 'Mi', 'Acero']\n"
     ]
    }
   ],
   "source": [
    "print(limpia_texto(text1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observamos las diferencias antes y después de aplicar la limpieza para el texto 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Partir', 'en', 'cuerpo', 'y', 'alma', 'partir.', 'Partir', 'deshacerse', 'de', 'las', 'miradas', 'piedras', 'opresoras', 'que', 'duermen', 'en', 'la', 'garganta.', 'He', 'de', 'partir', 'no', 'más', 'inercia', 'bajo', 'el', 'sol', 'no', 'más', 'sangre', 'anonadada', 'no', 'más', 'fila', 'para', 'morir.', 'He', 'de', 'partir', 'Pero', 'arremete', '¡viajera!']\n"
     ]
    }
   ],
   "source": [
    "Prueba = text2.split()\n",
    "print(Prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Partir', 'En', 'Cuerpo', 'Y', 'Alma', 'Partir', 'Partir', 'Deshacerse', 'De', 'Las', 'Miradas', 'Piedras', 'Opresoras', 'Que', 'Duermen', 'En', 'La', 'Garganta', 'He', 'De', 'Partir', 'No', 'Más', 'Inercia', 'Bajo', 'El', 'Sol', 'No', 'Más', 'Sangre', 'Anonadada', 'No', 'Más', 'Fila', 'Para', 'Morir', 'He', 'De', 'Partir', 'Pero', 'Arremete', 'Viajera']\n"
     ]
    }
   ],
   "source": [
    "print(limpia_texto(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto1_limpio = limpia_texto(text1) # Limpiamos el texto 1\n",
    "texto2_limpio = limpia_texto(text2) # Limpiamos el texto 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizando y tipificando\n",
    "\n",
    "Una vez que contamos con nuestros datos limpios, podemos proceder, ahora sí, a realizar la tokenización y tipificación de cada texto. \n",
    "\n",
    "Teniendo en cuenta que la tokenización no es más que el conteo de palabras en un texto, basta con calcular la longitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tipifica(texto):\n",
    "    \"\"\"\n",
    "    @author: Jonathan Martiñón\n",
    "    \n",
    "    La presente función recibe una lista de palabras\n",
    "    para la cual realizará tipificación, devolviendo\n",
    "    el total de tipos.\n",
    "    \n",
    "    Parámetros:\n",
    "    \n",
    "    texto   Será la lista de palabras a tipificar   LIST\n",
    "    \"\"\"\n",
    "    tipos = {} # Haremos uso de nuestros diccionarios\n",
    "    \n",
    "    for palabra in texto: # Analizamos cada palabra\n",
    "        \n",
    "        valor = tipos.get(palabra,0)+1 # En caso de que la palabra ya exista, le sumaremos 1\n",
    "                                       # pues encontramos otra ocurrencia, en caso de que no\n",
    "                                       # esté registrada, la iniciaremos con 1\n",
    "        tipos.update({palabra:valor})\n",
    "        \n",
    "    # A final, devolvemos la cantidad de tipos\n",
    "    return len(tipos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observamos los tipos del texto 1\n",
    "tipifica(texto1_limpio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Observamos los tipos del texto 2\n",
    "tipifica(texto2_limpio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Mostrando los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Genera_Reporte(textos,nombres):\n",
    "    \"\"\"\n",
    "    @author: Jonathan Martiñón\n",
    "    \n",
    "    La presente función recibe una lista de listas, donde\n",
    "    cada lista interna es una lista de palababras\n",
    "    para la cual realizará tipificación, y tokenización\n",
    "    devolviendo, a partir de ello, generará una tabla\n",
    "    mostrando los resultados.\n",
    "    \n",
    "    Parámetros:\n",
    "    \n",
    "    -nombres  Será la lista que contiene el       LIST\n",
    "              nombre correspondiente al texto\n",
    "             \n",
    "    -textos   Será la lista de textos a trabajar   LIST\n",
    "    \n",
    "    Ejemplo de parámetro:\n",
    "    \n",
    "    textos = [ [ \"PalabraTexto1\",\"PalabraTexto1\",\"PalabraTexto1\"],\n",
    "              [ \"PalabraTexto2\",\"PalabraTexto2\",\"PalabraTexto2\"] ]\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(len(textos)):\n",
    "        print(\"-----------------------------------\")\n",
    "        print(\"-----------------------------------\")\n",
    "        print(f\"Texto {i+1}: {nombres[i]}\\n\")\n",
    "        \n",
    "        tokens = len(textos[i]) # Capturamos los tokens\n",
    "        tipos = tipifica(textos[i]) # Capturamos los tipos\n",
    "        \n",
    "        print(f\"Tokens: {tokens}\")\n",
    "        print(f\"tipos: {tipos}\")\n",
    "    print(\"-----------------------------------\")\n",
    "    print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la tokenización y tipificación de textos\n",
      "\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "Texto 1: Dulce María Loynaz\n",
      "\n",
      "Tokens: 92\n",
      "tipos: 49\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "Texto 2: Última Inocencia\n",
      "\n",
      "Tokens: 42\n",
      "tipos: 30\n",
      "-----------------------------------\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Resultados de la tokenización y tipificación de textos\\n\")\n",
    "Genera_Reporte([texto1_limpio,texto2_limpio],[\"Dulce María Loynaz\", \"Última Inocencia\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
